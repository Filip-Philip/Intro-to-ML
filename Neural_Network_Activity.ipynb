{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP9F0bm-l78t"
      },
      "source": [
        "# Leren: Neural Networks and Automatic Differentiation\n",
        "## 12 December\n",
        "\n",
        "In today's lecture, we will use this notebook to help us get a better understanding of *neural networks* and implement a basic one for a regression problem. Perform the exercise in your own copy of the notebook: *File > Save a copy in Drive*\n",
        "\n",
        "Below, we're going to import `numpy` in a slightly different way.  We are going to import it from the library [JAX](https://github.com/google/jax).  Note that you'll (probably) see the warning: `WARNING:absl:No GPU/TPU found, falling back to CPU.`  This is expected, as it just means that the operations will be run on the CPU instead of a GPU (which would be faster, but performance shouldn't be a problem for this exercise)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ0ytgUWmTXA"
      },
      "outputs": [],
      "source": [
        "# We going to import numpy slightly differently, from the jax library.  \n",
        "# The reason for the change will be obvious later in the assignment\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, vmap\n",
        "\n",
        "# Some plotting libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_theme()\n",
        "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHEi1PTEs354"
      },
      "source": [
        "## TASK #1: Activation Functions\n",
        "\n",
        "\n",
        "1. Implement the [sigmoid](#sigmoid), [hyperbolic tangent](#tanh), and  [rectified linear](#relu) activation functions and their gradients\n",
        "2. Plot the [result, compare, and interpret](#compare-activations)\n",
        "3. Share your insights: https://www.menti.com/al29scze3vbc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkQls5K4l78y"
      },
      "source": [
        "<a name='sigmoid'></a>\n",
        "### Sigmoid Function\n",
        "\n",
        "The sigmoid (a.k.a. logistic) function is defined as:\n",
        "\n",
        "$$g(x) = \\frac{1}{1 + e^{-x}} $$\n",
        "\n",
        "**Task:** Write the function `sigmoid` that can either take a single value `X`, or an array of values `X`, and compute the *Sigmoid* function for each.  \n",
        "\n",
        "*Hint: Numpy built-in functions and basic arithmetic operations work on both Numpy arrays and single values.*\n",
        "\n",
        "**Task:** Write the function `grad_sigmoid` that takes a single value `X` and computes the derivative of the *Sigmoid* function.\n",
        "\n",
        "*Hint: Use the JAX function `grad`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jJKITZFl78y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "14bf3daa-7ef7-4f01-9271-f32ce2a73a04"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-0a79387cc716>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    return ??\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def sigmoid(X):\n",
        "    # X: scalar, vector, or matrix\n",
        "    # return: element-wise application of the sigmoid function\n",
        "    ### YOUR SOLUTION HERE\n",
        "    return ??\n",
        "\n",
        "assert sigmoid(0) == 0.5\n",
        "assert sigmoid(1) == np.e / (1 + np.e)\n",
        "assert np.allclose(sigmoid(np.array([0,1])), np.array([0.5, np.e / (1 + np.e)]))\n",
        "\n",
        "### YOUR SOLUTION HERE\n",
        "grad_sigmoid = ??\n",
        "\n",
        "assert grad_sigmoid(0.) == sigmoid(0.)*(1.-sigmoid(0.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMqs9thpunFp"
      },
      "source": [
        "<a name='tanh'></a>\n",
        "### Hyperbolic Tangent Function\n",
        "\n",
        "The tanh function is defined as:\n",
        "\n",
        "$$g(x) = \\frac{e^{2x}-1}{e^{2x}+1} $$\n",
        "\n",
        "**Task:** Write the function `tanh` that can either take a single value `X`, or an array of values `X`, and compute the *tanh* function for each.  \n",
        "\n",
        "*Hint: Numpy built-in functions and basic arithmetic operations work on both Numpy arrays and single values.*\n",
        "\n",
        "**Task:** Write the function `grad_tanh` that takes a single value `X` and computes the derivative of the *tanh* function.\n",
        "\n",
        "*Hint: Use the JAX function `grad`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSe7G6w8unFw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "0630b0dc-c214-40a2-81e0-085ee2681617"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-31c1428454cc>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    return ??\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def tanh(X):\n",
        "    # X: scalar, vector, or matrix\n",
        "    # return: element-wise application of the tanh function\n",
        "    ### YOUR SOLUTION HERE\n",
        "    return ??\n",
        "\n",
        "assert tanh(0) == 0.\n",
        "assert tanh(1) == (np.e**2-1.) / (1 + np.e**2)\n",
        "assert np.allclose(tanh(np.array([0,1])), np.array([0., (np.e**2-1.) / (1 + np.e**2)]))\n",
        "\n",
        "### YOUR SOLUTION HERE\n",
        "grad_tanh = ??\n",
        "\n",
        "assert grad_tanh(0.) == 1.-tanh(0.)**2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUm88HzKvuEL"
      },
      "source": [
        "<a name='relu'></a>\n",
        "### Rectified Linear Unit Function\n",
        "\n",
        "The ReLU function is defined as:\n",
        "\n",
        "$$g(x) = \\max(0,x) $$\n",
        "\n",
        "**Task:** Write the function `relu` that can either take a single value `X`, or an array of values `X`, and compute the *ReLU* function for each.  \n",
        "\n",
        "*Hint: Numpy built-in functions and basic arithmetic operations work on both Numpy arrays and single values.*\n",
        "\n",
        "\n",
        "**Task:** Write the function `grad_relu` that takes a single value `X` and computes the derivative of the *ReLU* function.\n",
        "\n",
        "*Hint: Use the JAX function `grad`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMWFRr0IwKkp"
      },
      "outputs": [],
      "source": [
        "def relu(X):\n",
        "    # X: scalar, vector, or matrix\n",
        "    # return: element-wise application of the relu function\n",
        "    ### YOUR SOLUTION HERE\n",
        "    return ??\n",
        "\n",
        "assert relu(0) == 0\n",
        "assert relu(1) == 1.\n",
        "assert np.allclose(relu(np.array([0,1])), np.array([0., 1.]))\n",
        "\n",
        "### YOUR SOLUTION HERE\n",
        "grad_relu = ??\n",
        "\n",
        "assert grad_relu(-1.) == 0.\n",
        "assert grad_relu(1.) == 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1HTM7Sy4htZ"
      },
      "source": [
        "<a name='compare-activations'></a>\n",
        "### Compare Activation Functions\n",
        "\n",
        "Here we will compare the different activation functions in terms of their function and gradient curves. I have provided scripts for producing the plots below.\n",
        "\n",
        "**Task:** Run the cells to generate the plots and discuss with your neighbour. How do the activation functions and their gradients differ? How do you think this impacts the neural network perfomance? (training, accuracy, flexibility, ...)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-WDSsHz4htf"
      },
      "outputs": [],
      "source": [
        "# Plot the functions\n",
        "plt.figure(figsize=(9,6))\n",
        "X = np.linspace(-3.,3.,100)\n",
        "plt.plot(X, sigmoid(X), label=\"$\\sigma(x)$\")\n",
        "plt.plot(X, tanh(X), label=\"$\\mathrm{tanh}(x)$\")\n",
        "plt.plot(X, relu(X), label=\"$\\mathrm{ReLU}(x)$\")\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTfl9aE_7sjJ"
      },
      "outputs": [],
      "source": [
        "# Plot the gradients \n",
        "# Note that JAX grad-based functions expects scalar outputs, vmap solves this\n",
        "# problem by applying the gradient function to each dimension of the input X.\n",
        "plt.figure(figsize=(9,6))\n",
        "X = np.linspace(-3.,3.,100)\n",
        "plt.plot(X, vmap(grad_sigmoid)(X), label=\"$\\\\frac{\\partial}{\\partial x}\\sigma(x)$\")\n",
        "plt.plot(X, vmap(grad_tanh)(X), label=\"$\\\\frac{\\partial}{\\partial x}\\mathrm{tanh}(x)$\")\n",
        "plt.plot(X, vmap(grad_relu)(X), label=\"$\\\\frac{\\partial}{\\partial x}\\mathrm{ReLU}(x)$\")\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ttqJTiXwAnn"
      },
      "source": [
        "## REGRESSION SETUP\n",
        "\n",
        "\n",
        "We will consider the following simulated scalar regression problem. Run the following cell to generate the training data and visualize the regression problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQlPMaw_wAnu",
        "outputId": "662f00d4-749e-4eb2-c0b9-b671b7f952aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def true_function(X):\n",
        "    # X: scalar, vector, or matrix\n",
        "    # return: f*(X)\n",
        "    return np.sin(X)\n",
        "\n",
        "N = 30\n",
        "key, subkey = random.split(random.PRNGKey(0))\n",
        "\n",
        "# Generate training data\n",
        "X_train = random.uniform(key=key,shape=(N,1),minval=0,maxval=6)\n",
        "Y_train = true_function(X_train) + 0.1*random.normal(key=subkey,shape=(N,1))\n",
        "\n",
        "# Plot the true function and training data\n",
        "plt.figure(figsize=(9,6))\n",
        "X = np.linspace(0.,6.,100)\n",
        "plt.plot(X, true_function(X), label=\"$f*(x)$\")\n",
        "plt.scatter(X_train[:], Y_train[:], marker='x', color='r', label='Training Data')\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FyIUQUWl780"
      },
      "source": [
        "## TASK #2: Forward Propagation\n",
        "\n",
        "Forward propagation consists of evaluating the output of the network $f(x_n)$ for a given datapoint $x_n$ and with $h_0 = x_n$:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "a_l &= W_{l-1}h_{l-1}+b_{l-1}& l=1,\\ldots,L  \\\\\n",
        "h_l &= \\sigma(a_l) & l=1,\\ldots,L \\\\\n",
        "f(x_n) &=W_L h_L + b_L\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where we call $a_l$ the *pre-activation*, i.e. the input to the activation function $\\sigma$.\n",
        "\n",
        "**Task:**\n",
        "1. Implement forward propagation in the function `predict` below using the `relu` activation function.\n",
        "2. Try a few different options of layer sizes, random seeds, noise scales for initialization and see how it affects the initial $\\hat{f}(x)$.\n",
        "3. What is the dimension of $f(x)$? https://www.menti.com/al29scze3vbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "zry4_Zod8NT_",
        "outputId": "bd31ab75-3e15-414a-f404-12682cdbf10b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-bfe70397004b>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    outputs = ??\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# A helper function to randomly initialize weights and biases\n",
        "# for a dense neural network layer using a Normal(0, scale^2) distribution\n",
        "def random_layer_params(m, n, key, scale=1e-1):\n",
        "  w_key, b_key = random.split(key)\n",
        "  return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
        "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
        "def init_network_params(sizes, key, scale=1e-1):\n",
        "  keys = random.split(key, len(sizes))\n",
        "  return [random_layer_params(m, n, k, scale) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
        "\n",
        "# ==============================================================================\n",
        "#                                 TASK\n",
        "# ==============================================================================\n",
        "def predict(params, inputs):\n",
        "    # params: list of neural network parameters, one set W, b per layer\n",
        "    # inputs: the input to the neural network X\n",
        "    # return: the output of forward propagation\n",
        "    for W, b in params:\n",
        "        ### YOUR SOLUTION HERE\n",
        "        outputs = ??\n",
        "        inputs = ??\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# Try different layer sizes, random seeds, and parameter initialization scales. \n",
        "# The first and last elements of the list correspond input and target dimensions.\n",
        "### YOUR SOLUTION HERE\n",
        "rnd_seed = 1\n",
        "layer_sizes = [1, 10, 10, 1]\n",
        "init_scale = 0.1\n",
        "# ==============================================================================\n",
        "\n",
        "# Initialize the network and setup vectorized function for prediction\n",
        "init_params = init_network_params(layer_sizes, random.PRNGKey(rnd_seed), init_scale)\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))\n",
        "\n",
        "# Plot the true function and training data\n",
        "plt.figure(figsize=(9,6))\n",
        "X = np.linspace(0.,6.,100)\n",
        "batched_preds = batched_predict(init_params, X.reshape((100,1)))\n",
        "plt.plot(X, true_function(X), label=\"$f*(x)$\")\n",
        "plt.plot(X, batched_preds[:], label='$\\hat{f}(x)$')\n",
        "plt.scatter(X_train[:], Y_train[:], marker='x', color='r', label='Training Data')\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHszE60ml782"
      },
      "source": [
        "## TASK #3: Backpropagation and Gradient Descent\n",
        "\n",
        "To compute gradients with respect to the neural network parameters we need to be able to evaluate the loss function\n",
        "$$\n",
        "\\ell( \\{W_l,b_l\\}_{l=0}^L; X, y) = \\sum_{n=1}^N \\|y_n-f(x_n)\\|^2\n",
        "$$\n",
        "\n",
        "**Task:**\n",
        "1. Implement the squared error loss function `loss` for a batch of data.\n",
        "\n",
        "Using JAX's `grad` function applied to `loss` we get a new callable function with the same arguments as `loss` that instead outputs the *gradient* with respect to the first argument (`params`). Using automatic differentiation we can avoid deriving the gradient of `loss` by hand.\n",
        "\n",
        "**Task:**\n",
        "2. Run gradient descent for various network architecturs, step sizes, and number of iterations. Can you get a good fit to the data? How does the step size interact with the neural network architecture (layer sizes)? ...\n",
        "3. Share your insights: https://www.menti.com/al29scze3vbc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "6l0bIAI-l784",
        "outputId": "3c19d8cd-88f2-4a05-b772-c8eef58a034f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-514b6c23c18e>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    return ??\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#                                 TASK\n",
        "# ==============================================================================\n",
        "def loss(params, batch):\n",
        "    # params: list of neural network parameters, one set W, b per layer\n",
        "    # batch: data in batch form\n",
        "    # return: squared error loss, scalar\n",
        "    inputs, targets = batch\n",
        "    preds = batched_predict(params, inputs)\n",
        "    ### YOUR SOLUTION HERE\n",
        "    return ??\n",
        "# ==============================================================================\n",
        "\n",
        "# Using JAX's grad function we get gradients of \n",
        "# loss w.r.t. the parameters\n",
        "grad_loss = grad(loss)\n",
        "\n",
        "init_params = init_network_params([1,5,1], random.PRNGKey(1))\n",
        "print('Loss test: '+str(loss(init_params, (X_train, Y_train)))) # expect scalar\n",
        "print('Grad test: '+str(grad_loss(init_params, (X_train,Y_train))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update(params, batch):\n",
        "    # params: list of neural network parameters, one set W, b per layer\n",
        "    # batch: data in batch form\n",
        "    # return: updated params after one iteration of gradient descent \n",
        "    grads = grad_loss(params, batch)\n",
        "    return [(w - step_size * dw, b - step_size * db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)]\n",
        "\n",
        "# ==============================================================================\n",
        "#                                 TASK\n",
        "# ==============================================================================\n",
        "\n",
        "### YOUR SOLUTION HERE \n",
        "# Hint: start with T small (~100) to make sure gradient descent is stable before\n",
        "# you run more iterations (usually T=1000 to 5000 is sufficient) \n",
        "T = 100\n",
        "layer_sizes = [1, 10, 10, 1]\n",
        "step_size = 0.01\n",
        "\n",
        "# ==============================================================================\n",
        "\n",
        "# Initialize and run gradient descent\n",
        "batched_data = (X_train, Y_train)\n",
        "params = init_network_params(layer_sizes, random.PRNGKey(1))\n",
        "loss_val = []\n",
        "for i in range(T):\n",
        "    params = update(params, batched_data)\n",
        "    loss_val.append(loss(params, batched_data))\n",
        "\n",
        "# Plot loss function\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(loss_val, label=\"Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel('Training Error/Loss')\n",
        "plt.title('Initial loss: '+str(np.round(loss_val[0],2))+\n",
        "          '  /  Final loss: '+str(np.round(loss_val[-1],2)))\n",
        "plt.show()\n",
        "\n",
        "# Plot the true function, training data, and learnt function\n",
        "plt.figure(figsize=(9,6))\n",
        "X = np.linspace(0.,6.,100)\n",
        "batched_preds = batched_predict(params, X.reshape((100,1)))\n",
        "plt.plot(X, true_function(X), label=\"$f*(x)$\")\n",
        "plt.plot(X, batched_preds[:], label='$\\hat{f}(x)$')\n",
        "plt.scatter(X_train[:], Y_train[:], marker='x', color='r', label='Training Data')\n",
        "plt.xlabel(\"$x$\")\n",
        "plt.title('Visualization')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "GSCImkFrX0Wy",
        "outputId": "1d872351-0c63-442e-8119-79b64952d9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6b2b9ecb9a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-6b2b9ecb9a84>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# batch: data in batch form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# return: updated params after one iteration of gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     return [(w - step_size * dw, b - step_size * db)\n\u001b[1;32m      7\u001b[0m           for (w, b), (dw, db) in zip(params, grads)]\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2654\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m     out_primal, out_vjp = ad.vjp(\n\u001b[0m\u001b[1;32m   2657\u001b[0m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[1;32m   2658\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_stack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_name_stack\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9063f28445f5>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(params, batch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# return: squared error loss, scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m### YOUR SOLUTION HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     axis_size_ = (axis_size if axis_size is not None else\n\u001b[1;32m   1681\u001b[0m                   _mapped_axis_size(fun, in_tree, args_flat, in_axes_flat, \"vmap\"))\n\u001b[0;32m-> 1682\u001b[0;31m     out_flat = batching.batch(\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vmap out_axes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-5b1ba4c2c84f>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(params, inputs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m### YOUR SOLUTION HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m__add__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__abs__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_radd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdeferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4934\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mswap\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4935\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_accepted_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4936\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rejected_binop_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4938\u001b[0m       raise TypeError(f\"unsupported operand type(s) for {opchar}: \"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m   '''\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreraise_with_filtered_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OBS: After the lecture before you leave, please complete the evaluation!"
      ],
      "metadata": {
        "id": "N2IAEGGAjCB9"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oHEi1PTEs354",
        "6ttqJTiXwAnn",
        "-FyIUQUWl780",
        "VHszE60ml782"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}